{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaoncsecu/BN-DRISHTI/blob/main/test_scripts/BN_DRISHTI_Run_On_Test_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2R2khd7Ucdl"
      },
      "source": [
        "##YoloV5 Setup..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Eed9mPSUbM1"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmOFnmWgiEId"
      },
      "source": [
        "###Downloading Models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kfVrSdgiDnF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path14 = \"/content/model\"\n",
        "if os.path.exists(path14) != True:\n",
        "  '''Downloading the model into CoLab temporary directory'''\n",
        "  !mkdir /content/model\n",
        "  !wget -P /content/model/ 'https://huggingface.co/crusnic/BN-DRISHTI/resolve/main/models/line_model_best.pt'\n",
        "  !wget -P /content/model/ 'https://huggingface.co/crusnic/BN-DRISHTI/resolve/main/models/word_model_best.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVu0zUTpMrvE"
      },
      "source": [
        "##Importing necessary libraries..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jIXND5rkQds"
      },
      "outputs": [],
      "source": [
        "from os.path import join\n",
        "import numpy as np\n",
        "import operator\n",
        "import cv2\n",
        "import fnmatch\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import glob\n",
        "import imutils\n",
        "from math import *\n",
        "from scipy.stats import mode\n",
        "from distutils.dir_util import copy_tree\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxTfq87ZG_Ku"
      },
      "source": [
        "##Unziping the input Images with Groundtruth..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuJznVIgGxqP"
      },
      "outputs": [],
      "source": [
        "def file_unzip(zip_file):\n",
        "  # Copying the dataset into colab local directory (for faster execution)\n",
        "  !unzip $zip_file -d \"/content\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_NWD38yAF1X"
      },
      "source": [
        "##Calculating IoU, DR, RA, FM by comparing Sorted line (labels) and GroundTruth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSLAUmJaqScJ"
      },
      "outputs": [],
      "source": [
        "# Sorting images, labels (ground, predict) on the list sequentially\n",
        "def sort_label(images, gt_labels, pred_labels):\n",
        "    sorted_img = []\n",
        "    sorted_gt_lb = []\n",
        "    sorted_pred_lb = []\n",
        "    ids = [img.split('_')[0] for img in images]\n",
        "    ids.sort(key=int)\n",
        "    for i in range(len(ids)):\n",
        "        for ele in images:\n",
        "            st = ele.split('_')[0]\n",
        "            if st == ids[i]:\n",
        "                sorted_img.append(ele)\n",
        "        for ele in gt_labels:\n",
        "            st = ele.split('_')[0]\n",
        "            if st == ids[i]:\n",
        "                sorted_gt_lb.append(ele)\n",
        "        for ele in pred_labels:\n",
        "            st = ele.split('_')[0]\n",
        "            if st == ids[i]:\n",
        "                sorted_pred_lb.append(ele)\n",
        "    return sorted_img, sorted_gt_lb, sorted_pred_lb\n",
        "\n",
        "\n",
        "# A function to convert the values (x, y, h, w) of Yolo to Pascal Voc\n",
        "def yolo_to_voc(width, height, x, y, w, h):\n",
        "    xmax = int((x * width) + (w * width) / 2.0)\n",
        "    xmin = int((x * width) - (w * width) / 2.0)\n",
        "    ymax = int((y * height) + (h * height) / 2.0)\n",
        "    ymin = int((y * height) - (h * height) / 2.0)\n",
        "    return (xmin, ymin, xmax, ymax)\n",
        "\n",
        "'''\n",
        "This function takes the predicted bounding box and ground truth bounding box and\n",
        "return the IoU ratio\n",
        "'''\n",
        "def calc_iou(gt_bbox, pred_bbox):\n",
        "    #print(gt_bbox)\n",
        "    x_topleft_gt, y_topleft_gt, x_bottomright_gt, y_bottomright_gt = gt_bbox\n",
        "\n",
        "    #print(x_topleft_gt, y_topleft_gt, x_bottomright_gt, y_bottomright_gt)\n",
        "\n",
        "    x_topleft_p, y_topleft_p, x_bottomright_p, y_bottomright_p = pred_bbox\n",
        "\n",
        "    if (x_topleft_gt > x_bottomright_gt) or (y_topleft_gt > y_bottomright_gt):\n",
        "        raise AssertionError(\"Ground Truth Bounding Box is not correct\")\n",
        "    if (x_topleft_p > x_bottomright_p) or (y_topleft_p > y_bottomright_p):\n",
        "        raise AssertionError(\"Predicted Bounding Box is not correct\", x_topleft_p, x_bottomright_p, y_topleft_p,\n",
        "                             y_bottomright_gt)\n",
        "\n",
        "    # if the GT bbox and predcited BBox do not overlap then iou=0\n",
        "    if (x_bottomright_gt < x_topleft_p):\n",
        "        # If bottom right of x-coordinate  GT  bbox is less than or above the top left of x coordinate of  the predicted BBox\n",
        "\n",
        "        return 0.0\n",
        "    if (\n",
        "            y_bottomright_gt < y_topleft_p):  # If bottom right of y-coordinate  GT  bbox is less than or above the top left of y coordinate of  the predicted BBox\n",
        "\n",
        "        return 0.0\n",
        "    if (\n",
        "            x_topleft_gt > x_bottomright_p):  # If bottom right of x-coordinate  GT  bbox is greater than or below the bottom right  of x coordinate of  the predcited BBox\n",
        "\n",
        "        return 0.0\n",
        "    if (\n",
        "            y_topleft_gt > y_bottomright_p):  # If bottom right of y-coordinate  GT  bbox is greater than or below the bottom right  of y coordinate of  the predcited BBox\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "    GT_bbox_area = (x_bottomright_gt - x_topleft_gt + 1) * (y_bottomright_gt - y_topleft_gt + 1)\n",
        "    Pred_bbox_area = (x_bottomright_p - x_topleft_p + 1) * (y_bottomright_p - y_topleft_p + 1)\n",
        "\n",
        "    x_top_left = np.max([x_topleft_gt, x_topleft_p])\n",
        "    y_top_left = np.max([y_topleft_gt, y_topleft_p])\n",
        "    x_bottom_right = np.min([x_bottomright_gt, x_bottomright_p])\n",
        "    y_bottom_right = np.min([y_bottomright_gt, y_bottomright_p])\n",
        "\n",
        "    intersection_area = (x_bottom_right - x_top_left + 1) * (y_bottom_right - y_top_left + 1)\n",
        "\n",
        "    union_area = (GT_bbox_area + Pred_bbox_area - intersection_area)\n",
        "\n",
        "    return intersection_area / union_area\n",
        "\n",
        "def multiple_image_result(iou_tresh, image_path, images, gt_labels, pred_labels, save_path):\n",
        "\n",
        "    # Declaring & initializing all necessary variables\n",
        "    avg_iou = []\n",
        "    avg_precision = []\n",
        "    avg_recall = []\n",
        "    # iou_thr1 = 0.5\n",
        "    # iou_thr2 = 0.85\n",
        "    iou_thr2 = iou_tresh\n",
        "    o2o = []\n",
        "    N = []\n",
        "    M = []\n",
        "    DR = []\n",
        "    RA = []\n",
        "\n",
        "    # Taking Single images from image list with for loop Starts Here\n",
        "    for i in range(len(images)):\n",
        "\n",
        "        # Taking image_path, groundtruth & prediction label for single image\n",
        "        img_path = image_path + images[i]\n",
        "        gt_lb_path = gt_path + gt_labels[i]\n",
        "        pred_lb_path = pred_path + pred_labels[i]\n",
        "\n",
        "        # Taking an image dimention (height, width) & Channels type (here, rgb = 3) of single image\n",
        "        img = cv2.imread(img_path)\n",
        "        height, width, channels = img.shape\n",
        "\n",
        "        # Reading labels (groundtruth & prediction) of single image from given path\n",
        "        fl = open(gt_lb_path, 'r')\n",
        "        f2 = open(pred_lb_path, 'r')\n",
        "        gt_lb_data = fl.readlines()\n",
        "        pred_lb_data = f2.readlines()\n",
        "        fl.close()\n",
        "        f2.close()\n",
        "\n",
        "        # Declaring list to store All lines values from label (groundtruth & prediction) of single image\n",
        "        all_gt_lb = []\n",
        "        all_pred_lb = []\n",
        "\n",
        "        # Storing all values line by line into all_gt_lb list from Groundtruth label of single image\n",
        "        for dt in gt_lb_data:\n",
        "            class_id, x, y, w, h = map(float, dt.split(' '))\n",
        "            new_label = list(yolo_to_voc(width, height, x, y, w, h))\n",
        "            all_gt_lb.append(new_label)\n",
        "\n",
        "        # Storing all values line by line into all_pred_lb list from Prediction label of single image\n",
        "        for dt in pred_lb_data:\n",
        "            class_id, x, y, w, h, conf = map(float, dt.split(' '))\n",
        "            new_label = list(yolo_to_voc(width, height, x, y, w, h))\n",
        "            all_pred_lb.append(new_label)\n",
        "\n",
        "        # Declaring a list to store IoU's of a single image\n",
        "        ious = []\n",
        "        '''\n",
        "        Doing comparison with a prediction line value to all groundtruth line value one by one. \n",
        "        So that we can take the closest values and take the IoU for each prediction line and store it in ious list. \n",
        "        '''\n",
        "        for ipb, pred_box in enumerate(all_pred_lb):\n",
        "            for igb, gt_box in enumerate(all_gt_lb):\n",
        "                iou = calc_iou(gt_box, pred_box)\n",
        "                temp = iou_thr2\n",
        "                if iou > iou_thr2:\n",
        "                    ious.append(iou)\n",
        "\n",
        "        '''\n",
        "        Here we are taking o2o = one to one matchs and N = Number of lines in the groundtruth, \n",
        "        M = Number of lines in the Prediction... per image. Then calculating DR & RA per image.\n",
        "        '''\n",
        "        o2o_per_img = len(ious)\n",
        "        N_per_img = len(all_gt_lb)\n",
        "        M_per_img = len(all_pred_lb)\n",
        "\n",
        "        o2o.append(o2o_per_img)\n",
        "        N.append(N_per_img)\n",
        "        M.append(M_per_img)\n",
        "\n",
        "\n",
        "        '''\n",
        "        As we have a list of IoU per image in ious, so here we are adding all the IoU's in for loop.\n",
        "        Then dividing it with list length. As a result we are getting append IoU for single image in avg_iou in one iteration\n",
        "        and eventually at the end of the loop all the IoU's for every image in the directory will be in avg_iou list... \n",
        "        '''\n",
        "        # per_img_iou = 0\n",
        "        # for i in range(len(ious)):\n",
        "        #     per_img_iou += ious[i]\n",
        "        # avg_iou.append(per_img_iou/len(ious))\n",
        "\n",
        "        per_img_iou = 0\n",
        "        if N_per_img != 0:\n",
        "            per_line_iou = 0\n",
        "            for i in range(len(ious)):\n",
        "                per_line_iou += ious[i]\n",
        "            per_img_iou = per_line_iou / N_per_img\n",
        "            avg_iou.append(per_img_iou)\n",
        "        else:\n",
        "            avg_iou.append(per_img_iou)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Taking Single images from image list with for loop Ends Here\n",
        "\n",
        "    '''\n",
        "    As we are out of the loop, now we have IoU for every image in avg_iou list. \n",
        "    Here we are summing all the IoU's in avg_sum_iou...\n",
        "    '''\n",
        "    avg_sum_iou = 0\n",
        "    for i in range(len(avg_iou)):\n",
        "        avg_sum_iou += avg_iou[i]\n",
        "\n",
        "    # In order to show IoU's of corresponding image together, we are zipping it and printing it out...\n",
        "    print(\"Images with IoU's :::\")\n",
        "    for img, iou in zip(images, avg_iou):\n",
        "        print(img, iou)\n",
        "    \n",
        "    # save_path = '/content/Final_Results/'\n",
        "    # file_name = \"Results_o2o_N_M_IoU_DR_RA_FM.txt\"\n",
        "    file_name = \"Results_o2o_N_M_IoU_DR_RA_FM_@\"+str(iou_thr2)+\".txt\"\n",
        "    completeName = os.path.join(save_path, file_name)\n",
        "    f = open(completeName, \"w+\")\n",
        "\n",
        "    dr = 0\n",
        "    ra = 0\n",
        "    fm = 0\n",
        "\n",
        "    f.write(\"Given Treshold: %f\\n\" %temp)\n",
        "    f.write(\"Images - o2o - N - M - IoU - DR - RA - FM :::\\n\")\n",
        "    print(\"Images-o2o-N-M-IoU-DR-RA-FM :::\")\n",
        "    for img, o2, n, m, iou in zip(images, o2o, N, M, avg_iou):\n",
        "        dr = o2 / n\n",
        "        ra = o2 / m\n",
        "        fm = (2 * dr * ra) / (dr + ra)\n",
        "        print(img, o2, n, m, iou, dr, ra, fm)\n",
        "        f.write(\"%s, %i, %i, %i, %.2f, %.2f, %.2f, %.2f\\n\" % (img, o2, n, m, iou, dr, ra, fm))\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "\n",
        "    # Calculating final IoU By dividing avg_sum_iou by length of list length of avg_iou which is 150\n",
        "    Final_IoU = avg_sum_iou/(len(avg_iou))\n",
        "    print(\"Average IoU for 150 images (Final IoU of Dataset) :: {}\".format(Final_IoU))\n",
        "\n",
        "    # o2o Starts\n",
        "    Final_o2o = 0\n",
        "    for j in range(len(o2o)) :\n",
        "        Final_o2o += o2o[j]\n",
        "    print(Final_o2o)\n",
        "\n",
        "    # N Starts\n",
        "    Final_N = 0\n",
        "    for j in range(len(N)):\n",
        "        Final_N += N[j]\n",
        "    print(Final_N)\n",
        "\n",
        "    # M Starts\n",
        "    Final_M = 0\n",
        "    for j in range(len(M)):\n",
        "        Final_M += M[j]\n",
        "    print(Final_M)\n",
        "\n",
        "    f.write(\"\\nFinal (IoU - o2o - N - M) :::\\n\")\n",
        "    f.write(\"%f, %s, %s, %s\\n\" % (Final_IoU, Final_o2o, Final_N, Final_M))\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    DR = Final_o2o/Final_N\n",
        "    RA = Final_o2o/Final_M\n",
        "\n",
        "    print(\"Detection Rate(Recall) :: {}\".format(DR))\n",
        "    print(\"Recognition Rate(Precision) :: {}\".format(RA))\n",
        "\n",
        "    # Calculating final performance and printing it out...\n",
        "    FM = ((2 * DR) * RA) / (DR + RA)\n",
        "    print(\"Final Performance :: {}\".format(FM*100))\n",
        "\n",
        "    f.write(\"\\nDR - RA - FM :::\\n\")\n",
        "    f.write(\"%f, %f, %f\\n\" % (DR, RA, FM))\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.close()\n",
        "    f\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XkuYEEJoVE2"
      },
      "outputs": [],
      "source": [
        "def cal_iou_dr_ra_fm(iou_tresh, img_path, gt_path, pred_path, save_path):\n",
        "  images = os.listdir(img_path)\n",
        "  gt_labels = os.listdir(gt_path)\n",
        "  pred_labels = os.listdir(pred_path)\n",
        "\n",
        "  # Calling sort_label() and giving images, groundtruth and predict label to sort them sequentially\n",
        "  images, gt_labels, pred_labels = sort_label(images, gt_labels, pred_labels)\n",
        "\n",
        "  print(\"Sorted Lists :::\")\n",
        "  print(\"Images: \",images)\n",
        "  print(\"GroundTruth: \",gt_labels)\n",
        "  print(\"Prediction: \",pred_labels) \n",
        "\n",
        "  if (not gt_path):\n",
        "    print(\"You haven't given the GroundTruths of your Test Images!\")\n",
        "  else:\n",
        "    # Calling out multiple_image_result() to get the average IoUs, DR, RA of dataset...\n",
        "    multiple_image_result(iou_tresh, img_path, images, gt_labels, pred_labels, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YjkUIpZio95"
      },
      "source": [
        "#**Detecting lines with YOLO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZoSKSkWVCSM"
      },
      "source": [
        "##**1st Detection: Detecting the Input Images** (Upload the given trained Line Model weights on your drive and assign its directory to the --weights command.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJHc0Bk-jGfI"
      },
      "source": [
        "Defining a function where we pass necessary attributes to detect lines by YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bsuxj8hFVHVN"
      },
      "outputs": [],
      "source": [
        "# Yolo Detection...\n",
        "def yolo_detection(img_path, img_size, conf):\n",
        "  # %cd yolov5\n",
        "  !python /content/yolov5/detect.py --weights /content/model/line_model_best.pt --img $img_size --conf $conf --source $img_path --save-conf --save-txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPI0Y0j6ofjl"
      },
      "source": [
        "##Sorted line (labels) after 1st detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUlmvvmTmO5P"
      },
      "outputs": [],
      "source": [
        "class Line_sort:\n",
        "    def __init__(self, txt_files, txt_loc):\n",
        "        self.txt_files = txt_files\n",
        "        self.txt_loc = txt_loc\n",
        "        self.read_file()\n",
        "\n",
        "    def read_file(self):\n",
        "        files = self.txt_files\n",
        "        os.mkdir('/content/sorted_line_after_1st_detection')\n",
        "        for file in files:\n",
        "            txt_file = []\n",
        "            file_loc = self.txt_loc+file\n",
        "            with open(file_loc, 'r' , encoding='utf-8',errors='ignore') as lines:\n",
        "                for line in lines:\n",
        "                    print(line)\n",
        "                    token = line.split()\n",
        "                    print(token)\n",
        "                    _, x, y, w, h, conf = map(float, line.split(' '))\n",
        "                    print(\"width -> \",w)\n",
        "                    print(\"confidence -> \",conf)\n",
        "                    if w > 0.50 and conf < 0.50:\n",
        "                      continue\n",
        "                    else:\n",
        "                      txt_file.append(token)\n",
        "            sorted_txt_file = sorted(txt_file, key=operator.itemgetter(2))\n",
        "            # print(sorted_txt_file)\n",
        "            lenght = len(sorted_txt_file[0])\n",
        "            self.file_write(sorted_txt_file, file)\n",
        "\n",
        "    def file_write(self,txt_file, file_name):\n",
        "        loc = '/content/sorted_line_after_1st_detection/'+file_name\n",
        "        with open(loc, 'w') as f: \n",
        "            c=0\n",
        "            for line in txt_file:  \n",
        "                for l in line:\n",
        "                    c+=1\n",
        "                    if c == len(line):\n",
        "                        f.write('%s' % l)\n",
        "                    else:\n",
        "                        f.write('%s ' % l)\n",
        "                f.write(\"\\n\")\n",
        "                c=0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs1UEhQckX4V"
      },
      "outputs": [],
      "source": [
        "def sort_detection_label(txt_loc):\n",
        "  txt_files = os.listdir(txt_loc)\n",
        "  obj = Line_sort(txt_files,txt_loc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n7ryDgRp0ZK"
      },
      "source": [
        "##1st Line Segment from Sorted line (labels) after 1st detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KbZUN9tp1Hp"
      },
      "outputs": [],
      "source": [
        "# text file and image sorting\n",
        "def images_and_txtfile_sort(images, txt_file):\n",
        "    txt = []\n",
        "    image = []\n",
        "    for item in txt_file:\n",
        "        ch = \"\"\n",
        "        for c in item:\n",
        "            if c == \"_\":\n",
        "                break\n",
        "            ch += c\n",
        "        txt.append(ch)\n",
        "\n",
        "    txt.sort(key=int)\n",
        "    sorted_txtfiles = []\n",
        "    sorted_images = []\n",
        "\n",
        "    for i in range(len(txt)):\n",
        "        for ele, ele2 in zip(txt_file, images):\n",
        "            st = \"\"\n",
        "            st2 = \"\"\n",
        "            for ch in ele:\n",
        "                if ch == \"_\":\n",
        "                    break\n",
        "                st += ch\n",
        "            if st == txt[i]:\n",
        "                sorted_txtfiles.append(ele)\n",
        "            for ch in ele2:\n",
        "                if ch == \"_\":\n",
        "                    break\n",
        "                st2 += ch\n",
        "            if st2 == txt[i]:\n",
        "                sorted_images.append(ele2)\n",
        "    return sorted_images, sorted_txtfiles\n",
        "\n",
        "# line segmantation by yolo bounding box\n",
        "def line_segmantation(path, image_loc, txt_loc, images, txt_file):\n",
        "\n",
        "    image, txt_files = images_and_txtfile_sort(images, txt_file)\n",
        "\n",
        "    for image, txt in zip(image, txt_files):\n",
        "        # make folder name according to txt file\n",
        "        new_folder = txt[:-4]\n",
        "        new_folder_loc = path + new_folder\n",
        "        # create subfolder in Lines according to txt file\n",
        "        os.mkdir(new_folder_loc)\n",
        "        # current image location\n",
        "        current_image = image_loc + image\n",
        "        img = cv2.imread(current_image)\n",
        "        dh, dw, _ = img.shape\n",
        "        # current txt file location\n",
        "        current_txt = txt_loc + txt\n",
        "        fl = open(current_txt, 'r')\n",
        "        data = fl.readlines()\n",
        "        fl.close()\n",
        "        k=1\n",
        "        for dt in data:\n",
        "            # _, x, y, w, h = map(float, dt.split(' '))\n",
        "            _, x, y, w, h,  conf = map(float, dt.split(' '))\n",
        "            if w > 0.50 and w < 0.80:\n",
        "               x = 0.5\n",
        "               w = 1.0\n",
        "            l = int((x - w / 2) * dw)\n",
        "            r = int((x + w / 2) * dw)\n",
        "            t = int((y - h / 2) * dh)\n",
        "            b = int((y + h / 2) * dh)\n",
        "\n",
        "            crop = img[t:b, l:r]\n",
        "            cv2.imwrite(\"{}{}/{}_{}.jpg\".format(path, new_folder, new_folder, k), crop)\n",
        "            k += 1\n",
        "\n",
        "def take_valid_img(images):\n",
        "    image = []\n",
        "    valid_img_ext = [\"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"png\", \"PNG\"]\n",
        "    for img in images:\n",
        "        try:\n",
        "            ext = img.split('.')[1]\n",
        "            if ext not in valid_img_ext :\n",
        "                continue\n",
        "            else:\n",
        "                image.append(img)\n",
        "        except:\n",
        "            continue\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMEzFIDUreyj"
      },
      "outputs": [],
      "source": [
        "def line_segmentation(img_path, sorted_label):\n",
        "  current_directory = img_path\n",
        "  #print(current_directory)\n",
        "  current_directory1 = sorted_label\n",
        "  #print(current_directory1)\n",
        "  images = []  # take for all images\n",
        "  txt = []     # take for all txt files\n",
        "\n",
        "  # images\n",
        "  # take all files in list in current directory location\n",
        "  current_directory_files = os.listdir(current_directory) \n",
        "  #print(current_directory_files)\n",
        "  if not current_directory_files:\n",
        "      print(\"{} folder is empty!\")\n",
        "\n",
        "  # lines\n",
        "  # take all files in list in current directory1 location\n",
        "  current_directory_1_files = os.listdir(current_directory1)\n",
        "  if not current_directory_1_files:\n",
        "      print(\"Line folder is empty of {} !\")\n",
        "\n",
        "  txt_pattern = \"*.txt\"\n",
        "  # take all only image in images list from current directory files list\n",
        "  images1 = [entry for entry in current_directory_files]\n",
        "  images = take_valid_img(images1)\n",
        "\n",
        "  # take all only txt file in txt list from current directory1 files list\n",
        "  txt = [entry for entry in current_directory_1_files if fnmatch.fnmatch(entry, txt_pattern)]\n",
        "\n",
        "  os.mkdir('/content/croped_line_after_1st_detection')\n",
        "  path = \"/content/croped_line_after_1st_detection/\"\n",
        "  # calling the line segmantation function\n",
        "  line_segmantation(path, current_directory, current_directory1, images, txt)\n",
        "  print(\"Successful line segmantated in the {} folder\".format(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZHu2NcBO85n"
      },
      "source": [
        "#Rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aanTZP86jE_Q"
      },
      "source": [
        "DSkew by HaughLine..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYST30r3jIv-"
      },
      "outputs": [],
      "source": [
        "class ImgCorrect():\n",
        "    def __init__(self, img):\n",
        "        self.img = img\n",
        "        self.h, self.w, self.channel = self.img.shape\n",
        "        if self.w <= self.h:\n",
        "            self.scale = 700 / self.w\n",
        "            self.w_scale = 700\n",
        "            self.h_scale = self.h * self.scale\n",
        "            self.img = cv2.resize(self.img, (0, 0), fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "        else:\n",
        "            self.scale = 700 / self.h\n",
        "            self.h_scale = 700\n",
        "            self.w_scale = self.w * self.scale\n",
        "            self.img = cv2.resize(self.img, (0, 0), fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "        self.gray = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    def img_lines(self):\n",
        "        ret, binary = cv2.threshold(self.gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "        # cv2.imshow(\"bin\",binary)\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # rectangular structure\n",
        "        binary = cv2.dilate(binary, kernel)  # dilate\n",
        "        edges = cv2.Canny(binary, 50, 200)\n",
        "        # cv2.imshow(\"edges\", edges)\n",
        "        self.lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=20)\n",
        "        print(self.lines)\n",
        "        if self.lines is None:\n",
        "            print(\"Line segment not found\")\n",
        "            return None\n",
        "\n",
        "        lines1 = self.lines[:, 0, :]  # Extract as 2D\n",
        "        # print(lines1)\n",
        "        imglines = self.img.copy()\n",
        "        for x1, y1, x2, y2 in lines1[:]:\n",
        "            cv2.line(imglines, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "        return imglines\n",
        "\n",
        "    def search_lines(self):\n",
        "      lines = self.lines[:, 0, :]  # extract as 2D\n",
        "    \n",
        "      number_inexist_k = 0\n",
        "      sum_pos_k45 = number_pos_k45 = 0\n",
        "      sum_pos_k90 = number_pos_k90 = 0\n",
        "      sum_neg_k45 = number_neg_k45 = 0\n",
        "      sum_neg_k90 = number_neg_k90 = 0\n",
        "      sum_zero_k = number_zero_k = 0\n",
        "\n",
        "      for x in lines:\n",
        "          if x[2] == x[0]:\n",
        "              number_inexist_k += 1\n",
        "              continue\n",
        "          #print(degrees(atan((x[3] - x[1]) / (x[2] - x[0]))), \"pos:\", x[0], x[1], x[2], x[3], \"Slope:\",(x[3] - x[1]) / (x[2] - x[0]))\n",
        "          degree = degrees(atan((x[3] - x[1]) / (x[2] - x[0])))\n",
        "          #print(degree)\n",
        "          if 0 < degree < 45:\n",
        "              number_pos_k45 += 1\n",
        "              sum_pos_k45 += degree\n",
        "          if 45 <= degree < 90:\n",
        "              number_pos_k90 += 1\n",
        "              sum_pos_k90 += degree\n",
        "          if -45 < degree < 0:\n",
        "              number_neg_k45 += 1\n",
        "              sum_neg_k45 += degree\n",
        "          if -90 < degree <= -45:\n",
        "              number_neg_k90 += 1\n",
        "              sum_neg_k90 += degree\n",
        "          if x[3] == x[1]:\n",
        "              number_zero_k += 1\n",
        "\n",
        "      max_number = max(number_inexist_k, number_pos_k45, number_pos_k90, number_neg_k45,number_neg_k90, number_zero_k)\n",
        "      #print(number_inexist_k,number_pos_k45, number_pos_k90, number_neg_k45, number_neg_k90,number_zero_k)\n",
        "    \n",
        "      if max_number == number_inexist_k:\n",
        "          return 90\n",
        "      if max_number == number_pos_k45:\n",
        "          return sum_pos_k45 / number_pos_k45\n",
        "      if max_number == number_pos_k90:\n",
        "          return sum_pos_k90 / number_pos_k90\n",
        "      if max_number == number_neg_k45:\n",
        "          return sum_neg_k45 / number_neg_k45\n",
        "      if max_number == number_neg_k90:\n",
        "          return sum_neg_k90 / number_neg_k90\n",
        "      if max_number == number_zero_k:\n",
        "          return 0\n",
        "\n",
        "    def rotate_image(self, degree):\n",
        "        \"\"\"\n",
        "                 Positive angle counterclockwise rotation\n",
        "        :param degree:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        print(\"degree:\", degree)\n",
        "        if -45 <= degree <= 0:\n",
        "            degree = degree  # #negative angle clockwise\n",
        "        if -90 <= degree < -45:\n",
        "            degree = 90 + degree  # positive angle counterclockwise\n",
        "        if 0 < degree <= 45:\n",
        "            degree = degree  # positive angle counterclockwise\n",
        "        if 45 < degree <= 90:\n",
        "            degree = degree - 90  # negative angle clockwise\n",
        "        print(\"rotate degree:\", degree)\n",
        "\n",
        "        # degree = degree - 90\n",
        "        height, width = self.img.shape[:2]\n",
        "        heightNew = int(width * fabs(sin(radians(degree))) + height * fabs(\n",
        "            cos(radians(degree))))  # This formula refers to the previous content\n",
        "        widthNew = int(height * fabs(sin(radians(degree))) + width * fabs(cos(radians(degree))))\n",
        "\n",
        "        matRotation = cv2.getRotationMatrix2D((width / 2, height / 2), degree, 1)  # rotate degree counterclockwise\n",
        "        matRotation[0, 2] += (widthNew - width) / 2\n",
        "        # Because after rotation, the origin of the coordinate system is the upper left corner of the new image, so it needs to be converted according to the original image\n",
        "        matRotation[1, 2] += (heightNew - height) / 2\n",
        "\n",
        "        # Affine transformation, the background color is filled with white\n",
        "        imgRotation = cv2.warpAffine(self.img, matRotation, (widthNew, heightNew), borderValue=(255, 255, 255))\n",
        "        # imgRotation = cv2.warpAffine(self.img, matRotation, (widthNew, heightNew), borderValue=filled_color)\n",
        "\n",
        "        return imgRotation\n",
        "\n",
        "def dskew(line_path, img):\n",
        "    img_loc = line_path + img\n",
        "    im = cv2.imread(img_loc)\n",
        "\n",
        "    # Padding\n",
        "    bg_color = [255, 255, 255]\n",
        "    pad_img = cv2.copyMakeBorder(im,100,100,100,100,cv2.BORDER_CONSTANT,value=bg_color)\n",
        "\n",
        "    imgcorrect = ImgCorrect(pad_img)\n",
        "    lines_img = imgcorrect.img_lines()\n",
        "    print(type(lines_img))\n",
        "    if lines_img is None:\n",
        "        rotate = imgcorrect.rotate_image(0)\n",
        "    else:\n",
        "        degree = imgcorrect.search_lines()\n",
        "        rotate = imgcorrect.rotate_image(degree)\n",
        "\n",
        "    return rotate\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z74ua2n5edfb"
      },
      "source": [
        "HaughLine and Affine Transform..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_EISASVejAG"
      },
      "outputs": [],
      "source": [
        "rotate_line = \"/content/Rotated_line_by_HaughLine_Affine/\"\n",
        "os.mkdir(rotate_line)\n",
        "\n",
        "rotate_line_Dskew = \"/content/Final_Results/DSkew/\"\n",
        "# os.mkdir(rotate_line_Dskew)\n",
        "\n",
        "rotate_line_Haughline = \"/content/Final_Results/HaughLine_Affine/\"\n",
        "# os.mkdir(rotate_line_Haughline)\n",
        "\n",
        "exception = []\n",
        "\n",
        "# Degree conversion\n",
        "def DegreeTrans(theta):\n",
        "    res = theta / np.pi * 180\n",
        "    return res\n",
        "\n",
        "# Rotate the image degree counterclockwise (original size)\n",
        "def rotateImage(src, degree):\n",
        "    # The center of rotation is the center of the image\n",
        "    h, w = src.shape[:2]\n",
        "    # Calculate the two-dimensional rotating affine transformation matrix\n",
        "    RotateMatrix = cv2.getRotationMatrix2D((w / 2.0, h / 2.0), degree, 1)\n",
        "    #print(RotateMatrix)\n",
        "    # Affine transformation, the background color is filled with white\n",
        "    rotate = cv2.warpAffine(src, RotateMatrix, (w, h), borderValue=(255, 255, 255))\n",
        "\n",
        "    # Padding\n",
        "    bg_color = [255, 255, 255]\n",
        "    pad_image_rotate = cv2.copyMakeBorder(rotate,100,100,100,100,cv2.BORDER_CONSTANT,value=bg_color)\n",
        "\n",
        "    return pad_image_rotate\n",
        "\n",
        "# Calculate angle by Hough transform\n",
        "def CalcDegree(srcImage,canny_img):\n",
        "    lineimage = srcImage.copy()\n",
        "    # Detect straight lines by Hough transform\n",
        "    # The fourth parameter is the threshold, the greater the threshold, the higher the detection accuracy\n",
        "    try:\n",
        "        lines = cv2.HoughLines(canny_img, 1, np.pi / 180, 200)\n",
        "        # Due to different images, the threshold is not easy to set, because the threshold is set too high, so that the line cannot be detected, the threshold is too low, the line is too much, the speed is very slow\n",
        "        sum = 0\n",
        "        # Draw each line segment in turn\n",
        "        for i in range(len(lines)):\n",
        "            for rho, theta in lines[i]:\n",
        "                # print(\"theta:\", theta, \" rho:\", rho)\n",
        "                a = np.cos(theta)\n",
        "                b = np.sin(theta)\n",
        "                x0 = a * rho\n",
        "                y0 = b * rho\n",
        "                x1 = int(round(x0 + 1000 * (-b)))\n",
        "                y1 = int(round(y0 + 1000 * a))\n",
        "                x2 = int(round(x0 - 1000 * (-b)))\n",
        "                y2 = int(round(y0 - 1000 * a))\n",
        "                # Only select the smallest angle as the rotation angle\n",
        "                sum += theta\n",
        "                cv2.line(lineimage, (x1, y1), (x2, y2), (0, 0, 255), 1, cv2.LINE_AA)\n",
        "        average = sum / len(lines)\n",
        "        angle = DegreeTrans(average) - 90\n",
        "        return angle\n",
        "    except:\n",
        "        angle = 0.0\n",
        "        return angle\n",
        "\n",
        "def ready_for_rotate(line_path, img):\n",
        "    rotate_line = \"/content/Rotated_line_by_HaughLine_Affine/\"\n",
        "\n",
        "    img_loc = line_path + img\n",
        "    image = cv2.imread(img_loc)\n",
        "\n",
        "    org_width = image.shape[1]\n",
        "    org_height = image.shape[0]\n",
        "\n",
        "    img1 = image\n",
        "    im_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    edges = cv2.Canny(im_gray,50,150,apertureSize=3)\n",
        "    degree = CalcDegree(image,edges)\n",
        "    #print(\"Adjust angle:\", degree)\n",
        "    if degree == 0.0:\n",
        "        rotate = dskew(line_path, img)\n",
        "        \n",
        "        filename1 = rotate_line_Dskew + img\n",
        "        cv2.imwrite(filename1, rotate)\n",
        "        # filename = rotate_line_exception + img\n",
        "        filename = rotate_line + img\n",
        "        exception.append(img)\n",
        "        cv2.imwrite(filename, rotate)\n",
        "    else:\n",
        "        rotate = rotateImage(image, degree)\n",
        "\n",
        "        filename2 = rotate_line_Haughline + img\n",
        "        cv2.imwrite(filename2, rotate)\n",
        "\n",
        "        filename = rotate_line + img\n",
        "        cv2.imwrite(filename, rotate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Bxc6DtzClC"
      },
      "outputs": [],
      "source": [
        "def rotate_line(first_detection):\n",
        "  source = first_detection\n",
        "  dir = os.listdir(source)\n",
        "\n",
        "  for i in range(len(dir)):\n",
        "      line_path = source + dir[i] + \"/\"\n",
        "      line_dir = os.listdir(line_path)\n",
        "\n",
        "      for img in line_dir:\n",
        "          ready_for_rotate(line_path, img)\n",
        "\n",
        "  # Line Rotate by -90\n",
        "  os.chdir(\"/content/Rotated_line_by_HaughLine_Affine/\")\n",
        "  for file in glob.glob(\"*.jpg\"):\n",
        "      image = Image.open(file)\n",
        "      width, height = image.size\n",
        "      if height > width:\n",
        "          angle = -90\n",
        "          rotated = image.rotate(angle, expand=True)\n",
        "          rotated.save(file.replace(\".jpg\", \".jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex-uDVv2K5uO"
      },
      "source": [
        "Copy Directory content..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwqlI5etK9bp"
      },
      "outputs": [],
      "source": [
        "def copy_dir(from_dir, to_dir):\n",
        "  # copy subdirectory example\n",
        "  fromDirectory = from_dir\n",
        "  toDirectory = to_dir\n",
        "  os.mkdir(toDirectory)\n",
        "\n",
        "  copy_tree(fromDirectory, toDirectory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44W92o58K5r6"
      },
      "source": [
        "#**Final Line Segmentation (**Upload the given trained Line Model weights on your drive and assign its directory to the --weights command.**)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3TlGEAi8NEk"
      },
      "source": [
        "**However, assign the directory of the best weights of your YOLO Line model in --weights directory.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GwrbdPeO_Of"
      },
      "outputs": [],
      "source": [
        "def yolo_detection2(img_path, img_size, conf):\n",
        "  !python /content/yolov5/detect.py --weights /content/model/line_model_best.pt --img $img_size --conf $conf --source $img_path --save-conf --save-txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljNStjQPLluX"
      },
      "source": [
        "##Find undetected image in Yolo 2nd detection..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyzcpG3BPBzH"
      },
      "source": [
        "Defining a function to get those images that are not getting 2nd YOLO detection for their low dimension and putting those images with the final segmented images.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY3Wi1eHCVVJ"
      },
      "outputs": [],
      "source": [
        "def find_undetected_images():\n",
        "  img_path = \"/content/Rotated_line_by_HaughLine_Affine/\"\n",
        "  # detect_lb_path = \"/content/Rotated_line_by_HaughLine_Affine/runs/detect/exp/labels/\"\n",
        "  detect_lb_path = \"/content/yolov5/runs/detect/exp2/labels/\"\n",
        "  # os.mkdir(\"undetect_img\")\n",
        "  undetect_img_path = \"/content/Final_Results/Final_Line_Segmentation/\"\n",
        "  os.mkdir(undetect_img_path)\n",
        "\n",
        "  def take_valid_img(images):\n",
        "      image = []\n",
        "      valid_img_ext = [\"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"png\", \"PNG\"]\n",
        "      for img in images:\n",
        "          try:\n",
        "              ext = img.split('.')[1]\n",
        "              if ext not in valid_img_ext :\n",
        "                  continue\n",
        "              else:\n",
        "                  image.append(img)\n",
        "          except:\n",
        "              continue\n",
        "      return image\n",
        "\n",
        "  img1 = os.listdir(img_path)\n",
        "  img = take_valid_img(img1)\n",
        "  detect_lb = os.listdir(detect_lb_path)\n",
        "\n",
        "  def find_undetect_img(img,detect_lb):\n",
        "      img_lb = [im.split('.')[0] for im in img]\n",
        "      dt_lb = [dt.split('.')[0] for dt in detect_lb]\n",
        "      undt_lb = list(set(img_lb).difference(dt_lb))\n",
        "      undetect_img = []\n",
        "      detect_img = []\n",
        "      for lb in undt_lb:\n",
        "          for im in img:\n",
        "              im_lb = im.split('.')[0]\n",
        "              if lb == im_lb:\n",
        "                  undetect_img.append(im)\n",
        "              else:\n",
        "                  detect_img.append(im)\n",
        "      write_image(undetect_img)\n",
        "\n",
        "  def write_image(undt_img):\n",
        "      for im in undt_img:\n",
        "          filename = undetect_img_path+im\n",
        "          img = cv2.imread(img_path+im)\n",
        "          cv2.imwrite(filename,img)\n",
        "\n",
        "  find_undetect_img(img,detect_lb)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqVNIZSkmSf8"
      },
      "source": [
        "## 2nd Line Segmentation after Rotation..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkompzPsuXOO"
      },
      "source": [
        "Cropping line from Sorted line (labels) after 2nd detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Md5rO46ty2G"
      },
      "outputs": [],
      "source": [
        "def final_line_segmentation():\n",
        "  filename2 = \"/content/Final_Results/Final_Line_Segmentation/\"\n",
        "  list2 = os.listdir(filename2)\n",
        "\n",
        "  filename1 = \"/content/Rotated_line_by_HaughLine_Affine/\"\n",
        "  list1 = os.listdir(filename1)\n",
        "  # list1.remove(\"runs\")\n",
        "\n",
        "  undetected_img = list2\n",
        "  destination = filename2\n",
        "\n",
        "  # label_path = \"/content/Rotated_line_by_HaughLine_Affine/runs/detect/exp/\"\n",
        "  label_path = \"/content/yolov5/runs/detect/exp2/\"\n",
        "\n",
        "  exception = []\n",
        "  def arrange_images_labels(images, labels):\n",
        "      img_lb = {}\n",
        "      for img in images:\n",
        "          for lb in labels:\n",
        "              st_img = img.split('.')[0]\n",
        "              st_lb = lb.split('.')[0]\n",
        "              if st_img == st_lb:\n",
        "                  img_lb[img] = lb\n",
        "      return img_lb\n",
        "\n",
        "  def take_valid_img(images, undetected_img):\n",
        "      image = []\n",
        "      valid_img_ext = [\"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"png\", \"PNG\"]\n",
        "      for img in images:\n",
        "          try:\n",
        "              ext = img.split('.')[1]\n",
        "              if ext not in valid_img_ext :\n",
        "                  continue\n",
        "              else:\n",
        "                  image.append(img)\n",
        "          except:\n",
        "              continue\n",
        "      detected_img_val = [x for x in image if x not in undetected_img]\n",
        "      return detected_img_val\n",
        "\n",
        "\n",
        "  def crop_image(bb_data,destination,image,img_lb,dh,dw):\n",
        "      x = float(bb_data[1])\n",
        "      y = float(bb_data[2])\n",
        "      w = float(bb_data[3])\n",
        "      h = float(bb_data[4])\n",
        "    \n",
        "      # x = 0.5\n",
        "      # w  = 1.0\n",
        "      l = int((x - w / 2) * dw)\n",
        "      r = int((x + w / 2) * dw)\n",
        "      t = int((y - h / 2) * dh)\n",
        "      b = int((y + h / 2) * dh)\n",
        "\n",
        "      crop = image[t:b, l:r]\n",
        "      filename = destination+img_lb\n",
        "      cv2.imwrite(filename,crop)\n",
        "      \n",
        "    \n",
        "  # line segmantation by yolo bounding box\n",
        "  def line_segmantation(image_loc, txt_loc, images, txt_file, destination):\n",
        "      image_labels = arrange_images_labels(images, txt_file)\n",
        "\n",
        "      for img_lb, lb in image_labels.items():\n",
        "          img_name = lb[:-4]\n",
        "          current_image = image_loc + img_lb\n",
        "          image = cv2.imread(current_image)\n",
        "          dh, dw, _ = image.shape\n",
        "          current_txt = txt_loc + lb\n",
        "          fl = open(current_txt, 'r')\n",
        "          data = fl.readlines()\n",
        "          fl.close()\n",
        "          \n",
        "          max_w = 0\n",
        "          data1 = []\n",
        "          for line in data:\n",
        "              token = line.split()\n",
        "              data1.append(token)\n",
        "          \n",
        "          if len(data1)==1:\n",
        "              bb_data = data1[0]\n",
        "              wdth = float(bb_data[3])\n",
        "              if wdth>0.4:\n",
        "                  crop_image(bb_data,destination,image,img_lb,dh,dw,)\n",
        "              else:\n",
        "                  filename = destination+img_lb\n",
        "                  cv2.imwrite(filename,image)\n",
        "          elif len(data1)==2:\n",
        "              bb_data1 = data1[0]\n",
        "              bb_data2 = data1[1]\n",
        "              w1 = float(bb_data1[3]) \n",
        "              w2 = float(bb_data2[3])\n",
        "              # if w1 <= 0.5 and w2 <= 0.5:\n",
        "              #    max_w = max_w + 1\n",
        "              # if max_w == 2:\n",
        "              #   filename = destination+img_lb\n",
        "              #   cv2.imwrite(filename,image)\n",
        "              c1 = float(bb_data1[5]) \n",
        "              c2 = float(bb_data2[5])\n",
        "              if w1 <= 0.5 and w2 <= 0.5:\n",
        "                if c1 >= 0.8 and c2 >= 0.8:\n",
        "                  sorted_bb_data = sorted(data1, key=operator.itemgetter(5))\n",
        "                  bb_data = sorted_bb_data[-1]\n",
        "                  crop_image(bb_data,destination,image,img_lb,dh,dw,)\n",
        "                else:\n",
        "                  filename = destination+img_lb\n",
        "                  cv2.imwrite(filename,image)\n",
        "              else:\n",
        "                sorted_bb_data = sorted(data1, key=operator.itemgetter(3))\n",
        "                bb_data = sorted_bb_data[-1]\n",
        "                crop_image(bb_data,destination,image,img_lb,dh,dw,)\n",
        "          elif len(data1)==3:\n",
        "              sorted_bb_data = sorted(data1, key=operator.itemgetter(2))\n",
        "              bb_data = sorted_bb_data[1]\n",
        "              crop_image(bb_data,destination,image,img_lb,dh,dw,)\n",
        "          else:\n",
        "              sorted_bb_data = sorted(data1, key=operator.itemgetter(3))\n",
        "              bb_data = sorted_bb_data[-1]\n",
        "              crop_image(bb_data,destination,image,img_lb,dh,dw,)\n",
        "               \n",
        "  def read_files(filename1, label_path, undetected_img, destination):\n",
        "        image_directory = filename1\n",
        "        txt_label_directory = label_path + \"labels/\"\n",
        "        all_img_file = os.listdir(image_directory)\n",
        "\n",
        "        # take all files in list in current directory1 location\n",
        "        all_txt_labels = os.listdir(txt_label_directory)\n",
        "\n",
        "        images = take_valid_img(all_img_file, undetected_img) # image list\n",
        "        \n",
        "        txt_pattern = \"*.txt\"\n",
        "        all_pred_label = [entry for entry in all_txt_labels if fnmatch.fnmatch(entry, txt_pattern)]\n",
        "\n",
        "        if len(images) == len(all_pred_label):\n",
        "          line_segmantation(image_directory, txt_label_directory, images, all_pred_label, destination)\n",
        "          print(\"Successful line segmantation!\")\n",
        "        else:\n",
        "          print(\"Unsuccessful line segmantation!\")     \n",
        "\n",
        "\n",
        "  read_files(filename1, label_path, undetected_img, destination)     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBSJG5pHI0YD"
      },
      "source": [
        "Drawing Bounding Box in Segmented Lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM1oL9NTI7ZM"
      },
      "outputs": [],
      "source": [
        "def drawing_bounding_box():\n",
        "  rotate_line = \"/content/Final_Results/Segmented_line_with_bounding_box/\"\n",
        "  os.mkdir(rotate_line)\n",
        "\n",
        "  def bounding_box(im):\n",
        "      im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "      ret, thresh = cv2.threshold(im_gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "      edges = cv2.Canny(im_gray, 50, 150, apertureSize=3)\n",
        "      minLineLength = 1\n",
        "      maxLineGap = 10\n",
        "      try:\n",
        "          lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength, maxLineGap)\n",
        "          for line in lines:\n",
        "              for x1, y1, x2, y2 in line:\n",
        "                  cv2.line(thresh, (x1, y1), (x2, y2), (0), 3)\n",
        "\n",
        "          kernel = np.ones((3, 3), np.uint8)\n",
        "\n",
        "          thresh = cv2.dilate(thresh, kernel, iterations=9)\n",
        "          # thresh = cv2.morphologyEx(thresh,cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "          contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "          minArea = 900  # min area for to be considered\n",
        "          for cnt in contours:\n",
        "              area = cv2.contourArea(cnt)\n",
        "              if (area > minArea):\n",
        "                  rect = cv2.minAreaRect(cnt)\n",
        "                  box = cv2.boxPoints(rect)\n",
        "                  box = np.int0(box)\n",
        "                  print(box)\n",
        "                  cv2.drawContours(im, [box], 0, (0, 0, 255), 3)\n",
        "          return box, im\n",
        "      except:\n",
        "          box = [[]]\n",
        "          return box, im\n",
        "\n",
        "\n",
        "\n",
        "  def draw_bb(line_path, img):\n",
        "      img_loc = line_path + img\n",
        "      image = cv2.imread(img_loc)\n",
        "\n",
        "      box, bb_image = bounding_box(image)\n",
        "\n",
        "      filename = rotate_line + img\n",
        "      cv2.imwrite(filename, bb_image)\n",
        "\n",
        "  line_path = \"/content/Final_Results/Final_Line_Segmentation/\"\n",
        "  line_dir = os.listdir(line_path)\n",
        "\n",
        "  for img in line_dir:\n",
        "      draw_bb(line_path, img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJhKB_GwLKy4"
      },
      "source": [
        "Word Cropping of Segmented Lines..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06sWiIzSIzZA"
      },
      "outputs": [],
      "source": [
        "def word_cropping():\n",
        "  word = \"/content/Final_Results/crop_word_of_segmented_lines/\"\n",
        "  os.mkdir(word)\n",
        "  img_path = \"/content/Final_Results/Final_Line_Segmentation/\"\n",
        "  images = os.listdir(img_path)\n",
        "\n",
        "\n",
        "  def bounding_box(im):\n",
        "      im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "      ret, thresh = cv2.threshold(im_gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "      edges = cv2.Canny(im_gray, 50, 150, apertureSize=3)\n",
        "\n",
        "      minLineLength = 1\n",
        "      maxLineGap = 10\n",
        "      word_box = []\n",
        "      try:\n",
        "          lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength, maxLineGap)\n",
        "          for line in lines:\n",
        "              for x1, y1, x2, y2 in line:\n",
        "                  cv2.line(thresh, (x1, y1), (x2, y2), (0), 3)\n",
        "\n",
        "          kernel = np.ones((3, 3), np.uint8)\n",
        "          dilate = cv2.dilate(thresh, kernel, iterations=9)\n",
        "\n",
        "          contours, hierarchy = cv2.findContours(dilate, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "          minArea = 900  # min area for to be considered\n",
        "          for cnt in contours:\n",
        "              area = cv2.contourArea(cnt)\n",
        "              if (area > minArea):\n",
        "                  rect = cv2.minAreaRect(cnt)\n",
        "                  box = cv2.boxPoints(rect)\n",
        "                  box_rect = []\n",
        "                  x, y, w, h = cv2.boundingRect(box)\n",
        "                  box_rect.append(x)\n",
        "                  box_rect.append(y)\n",
        "                  box_rect.append(w)\n",
        "                  box_rect.append(h)\n",
        "                  word_box.append(box_rect)\n",
        "          return word_box\n",
        "      except:\n",
        "          return word_box\n",
        "\n",
        "  def word_crop(image,name,word_box):\n",
        "      sorted_word_box = sorted(word_box, key=operator.itemgetter(0))\n",
        "      dh,dw,_ = image.shape\n",
        "      k=1\n",
        "      im = image.copy()\n",
        "      for rect in sorted_word_box:\n",
        "          x = rect[0]\n",
        "          y = rect[1]\n",
        "          w = rect[2]\n",
        "          h = rect[3]\n",
        "          crop = im[y:y + h, x:x + w]\n",
        "          filename = word + name + \"/\" + name +\"_\"+str(k)+\".jpg\"\n",
        "          cv2.imwrite(filename, crop)\n",
        "          k+=1\n",
        "\n",
        "  def read_data(images):\n",
        "      for img in images:\n",
        "          name = img.split('.')[0]\n",
        "          folder = word+name\n",
        "          os.mkdir(folder)\n",
        "          im_path = img_path+img\n",
        "          im= cv2.imread(im_path)\n",
        "          bg = [255, 255, 255]\n",
        "          pad_img = cv2.copyMakeBorder(im.copy(), 100, 100, 100, 100, cv2.BORDER_CONSTANT, value=bg)\n",
        "          word_box = bounding_box(pad_img)\n",
        "          word_crop(pad_img,name,word_box)\n",
        "          print(img+\" -> word cropping is successful for line image!!\")\n",
        "\n",
        "  read_data(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUHiyEi0UEnh"
      },
      "source": [
        "Zipping and Downloading Results..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5zORuQRIIdW"
      },
      "outputs": [],
      "source": [
        "def zip_results():\n",
        "  os.mkdir(\"/content/test_results\")\n",
        "\n",
        "  # Zipping the test Results\n",
        "  !zip -r /content/test_results/Final_Results.zip /content/Final_Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3gAj3lIN5D8"
      },
      "source": [
        "##**Main function call starts from here.** (Upload the given BN-HTRd datasets zip version on your desire location, and assign the directory address of the dataset's zip version to the defined \"dataset_directory\" variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCqv5IQfHBty"
      },
      "outputs": [],
      "source": [
        "# Downloading the dataset zip from the given directory...\n",
        "dataset_directory = 'https://github.com/crusnic-corp/BN-DRISHTI/raw/main/test_scripts/test.zip'\n",
        "!wget -P /content/ $dataset_directory\n",
        "\n",
        "x = os.listdir(\"/content\")\n",
        "for i in x:\n",
        "  if i.endswith(('.zip')) == True:\n",
        "    zip_file = \"/content/\" + i\n",
        "    file_unzip(zip_file) # Unzipping the Zip file...\n",
        "    !rm -rf $zip_file # Removing downloaded zip file...\n",
        "    zip_lbl = i.split('.')[0] # Taking label of the dataset...\n",
        "    # Asigning image and label path according to our dataset structure...\n",
        "    img_path = \"/content/\" + zip_lbl + \"/images\"\n",
        "    gt_path = \"/content/\" + zip_lbl + \"/labels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNqXEN51i4TB"
      },
      "outputs": [],
      "source": [
        "# Making a folder to store all the results...\n",
        "os.mkdir(\"/content/Final_Results/\")\n",
        "\n",
        "# Image Path from unziped file...\n",
        "# Yolo 1st Detection...\n",
        "img_path = img_path + \"/\"\n",
        "img_size = 640\n",
        "conf = 0.30\n",
        "yolo_detection(img_path, img_size, conf)\n",
        "\n",
        "# Sorting Labels of 1st detection on the basis of y...\n",
        "txt_loc = \"/content/yolov5/runs/detect/exp/labels/\"\n",
        "sort_detection_label(txt_loc)\n",
        "\n",
        "# Line Segmentation after 1st Detection...\n",
        "sorted_label = \"/content/sorted_line_after_1st_detection\"\n",
        "sorted_label = sorted_label + \"/\"\n",
        "line_segmentation(img_path, sorted_label)\n",
        "\n",
        "#GroundTruth Path from unziped file......\n",
        "save_path = '/content/Final_Results/Line_Evaluation/'\n",
        "os.mkdir(save_path)\n",
        "iou_tresh_range = [0.7, 0.8, 0.85, 0.9]\n",
        "gt_path = gt_path + \"/\"\n",
        "# IoU FM DR RA Calculation...\n",
        "# pred_path = \"/content/yolov5/runs/detect/exp/labels/\"\n",
        "pred_path = \"/content/sorted_line_after_1st_detection/\"\n",
        "for i in iou_tresh_range:\n",
        "  iou_tresh = i\n",
        "  print(\"Given IoU: \",iou_tresh)\n",
        "  cal_iou_dr_ra_fm(iou_tresh, img_path, gt_path, pred_path, save_path)\n",
        "  print()\n",
        "\n",
        "# Only YOLO and without Filtering...\n",
        "# GroundTruth Path from unziped file......\n",
        "save_path = '/content/Final_Results/Line_Evaluation_only_YOLO/'\n",
        "os.mkdir(save_path)\n",
        "iou_tresh_range = [0.7, 0.8, 0.85, 0.9]\n",
        "gt_path = gt_path + \"/\"\n",
        "# IoU FM DR RA Calculation...\n",
        "pred_path = \"/content/yolov5/runs/detect/exp/labels/\"\n",
        "# pred_path = \"/content/sorted_line_after_1st_detection/\"\n",
        "for i in iou_tresh_range:\n",
        "  iou_tresh = i\n",
        "  print(\"Given IoU: \",iou_tresh)\n",
        "  cal_iou_dr_ra_fm(iou_tresh, img_path, gt_path, pred_path, save_path)\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mM6WO3CuCT3"
      },
      "outputs": [],
      "source": [
        "# Final prediction by YOLO...\n",
        "\n",
        "def draw_BB(img_path, label_path, flag):\n",
        "  img = cv2.imread(img_path)\n",
        "  dh, dw, _ = img.shape\n",
        "\n",
        "  lb = open(label_path, 'r')\n",
        "  data = lb.readlines()\n",
        "  lb.close()\n",
        "\n",
        "  for dt in data:\n",
        "    if flag == 0:\n",
        "      _, x, y, w, h = map(float, dt.split(' '))\n",
        "    else:\n",
        "      _, x, y, w, h, conf = map(float, dt.split(' '))\n",
        "    l = int((x - w / 2) * dw)\n",
        "    r = int((x + w / 2) * dw)\n",
        "    t = int((y - h / 2) * dh)\n",
        "    b = int((y + h / 2) * dh)\n",
        "    if flag == 0:\n",
        "      cv2.rectangle(img, (l, t), (r, b), (0, 250, 0), 2)\n",
        "    else:\n",
        "      cv2.rectangle(img, (l, t), (r, b), (250, 0, 0), 2)\n",
        "    \n",
        "  # plot_fig(img)\n",
        "  return img\n",
        "\n",
        "\n",
        "# For Predicted document image Red BB...\n",
        "# img_path = \"/content/offline_line_word_trainning/line_tranning/dataset_for_line_segmentation/test/images/\"\n",
        "img_path = \"/content/test/images/\"\n",
        "lb_path = \"/content/sorted_line_after_1st_detection/\"\n",
        "des = \"/content/Final_Results/Final_doc_image_detection/\"\n",
        "os.mkdir(des)\n",
        "img_list = os.listdir(img_path)\n",
        "flag = 1\n",
        "for i in img_list:\n",
        "  image_path = img_path + i\n",
        "  label_path = lb_path + i.split('.')[0] + \".txt\"\n",
        "  img_p = draw_BB(image_path, label_path, flag)\n",
        "  img_p1 = cv2.cvtColor(img_p, cv2.COLOR_BGR2RGB)\n",
        "  filename = des + i\n",
        "  cv2.imwrite(filename, img_p1)\n",
        "\n",
        "# For Ground truth document image Green BB...\n",
        "img_path_1 = \"/content/test/images/\"\n",
        "lb_path_1 = \"/content/test/labels/\"\n",
        "des_1 = \"/content/Final_Results/Doc_image_BB/\"\n",
        "os.mkdir(des_1)\n",
        "img_list_1 = os.listdir(img_path_1)\n",
        "flag = 0\n",
        "for i in img_list_1:\n",
        "  image_path_gt = img_path_1 + i\n",
        "  label_path_gt = lb_path_1 + i.split('.')[0] + \".txt\"\n",
        "  img_p_gt = draw_BB(image_path_gt, label_path_gt, flag)\n",
        "  img_p1_gt = cv2.cvtColor(img_p_gt, cv2.COLOR_BGR2RGB)\n",
        "  filename_1 = des_1 + i\n",
        "  cv2.imwrite(filename_1, img_p1_gt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clkdTNSvPqSS"
      },
      "outputs": [],
      "source": [
        "# Roation..Roatating image after 1st line Segmentation...\n",
        "rotate_line_Dskew = \"/content/Final_Results/DSkew/\"\n",
        "os.mkdir(rotate_line_Dskew)\n",
        "rotate_line_Haughline = \"/content/Final_Results/HaughLine_Affine/\"\n",
        "os.mkdir(rotate_line_Haughline)\n",
        "first_detection = \"/content/croped_line_after_1st_detection/\"\n",
        "rotate_line(first_detection)\n",
        "\n",
        "# Copy content from one directory to another...\n",
        "from_dir = \"/content/Rotated_line_by_HaughLine_Affine\"\n",
        "to_dir = \"/content/Final_Results/Rotated_line_by_HaughLine_Affine\"\n",
        "copy_dir(from_dir, to_dir)\n",
        "\n",
        "# Image Path from unziped file...\n",
        "# Yolo 2nd Detection...\n",
        "rotated_img_path = \"/content/Rotated_line_by_HaughLine_Affine/\"\n",
        "# img_size = 416\n",
        "img_size = 640\n",
        "conf = 0.50\n",
        "yolo_detection2(rotated_img_path, img_size, conf)\n",
        "\n",
        "# FINAL LINE SEGMENTATION :::\n",
        "# Undetected images from 2nd detection...\n",
        "find_undetected_images()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BI1O0u1GPWX"
      },
      "outputs": [],
      "source": [
        "# Crop detected Lines with max Width... \n",
        "final_line_segmentation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9onDjYun-UC"
      },
      "outputs": [],
      "source": [
        "# Taking image back to original shape...\n",
        "def trim_original_image(rotate, org_w, org_h):\n",
        "  org_width = org_w\n",
        "  org_height = org_h\n",
        "\n",
        "  img1 = rotate\n",
        "  width = img1.shape[1]\n",
        "  height = img1.shape[0]\n",
        "  print(\"Original height -> \",org_height)\n",
        "  print(\"Original width -> \",org_width)\n",
        "\n",
        "  start_row = 60\n",
        "  end_row = height - 60\n",
        "\n",
        "  start_col = 60\n",
        "  end_col = width - 60\n",
        "  img_new = img1[start_row:end_row, start_col:end_col]\n",
        "\n",
        "  width1 = img_new.shape[1]\n",
        "  height1 = img_new.shape[0]\n",
        "  print(\"New height -> \",height1)\n",
        "  print(\"New width -> \",width1)\n",
        "    \n",
        "  return img_new\n",
        "\n",
        "def plot_fig(img, size = 15):\n",
        "  plt.figure(figsize=(size, size))\n",
        "  plt.imshow(imutils.opencv2matplotlib(img))\n",
        "  plt.show()\n",
        "\n",
        "final_line_segment = \"/content/Final_Results/Final_Line_Segmentation/\"\n",
        "dskew_img_list = os.listdir(rotate_line_Dskew)\n",
        "print(dskew_img_list)\n",
        "for i in dskew_img_list:\n",
        "  temp = final_line_segment + i\n",
        "  img1 = cv2.imread(temp)\n",
        "  height, width, channels = img1.shape\n",
        "  temp2 = rotate_line_Dskew + i\n",
        "  img2 = cv2.imread(temp2)\n",
        "  height2, width2, channels = img2.shape\n",
        "  if height >= height2:\n",
        "    print(height2)\n",
        "    print(width2)\n",
        "    print(i)\n",
        "    # os.remove(temp)\n",
        "    temp3 = trim_original_image(img1, width, height)\n",
        "    cv2.imwrite(temp, temp3)\n",
        "    print(\"Original\")\n",
        "    # cv2_imshow(img1)\n",
        "    plot_fig(img1)\n",
        "    print(\"New\")\n",
        "    # cv2_imshow(temp3)\n",
        "    plot_fig(temp3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgmL54xiZkR7"
      },
      "source": [
        "# **Word Detection and Segmentation** (Upload the given trained Word Model weights on your drive and assign its directory to the --weights directory.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urpGfUGDai4X"
      },
      "outputs": [],
      "source": [
        "# %cd yolov5\n",
        "!python /content/yolov5/detect.py --weights /content/model/word_model_best.pt --img 640 --conf 0.40 --source /content/Final_Results/Final_Line_Segmentation --save-conf --save-txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE3z78fNZ0Qs"
      },
      "outputs": [],
      "source": [
        "# Copying directory content...\n",
        "from_dir = \"/content/yolov5/runs/detect/exp3\"\n",
        "to_dir = \"/content/Final_Results/Final_word_segmentation_result\"\n",
        "copy_dir(from_dir, to_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OR08vJoBizF"
      },
      "source": [
        "Draw Bounding Box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hodrEu3BnWj"
      },
      "outputs": [],
      "source": [
        "def draw_BB(img_path, label_path, flag):\n",
        "  img = cv2.imread(img_path)\n",
        "  dh, dw, _ = img.shape\n",
        "\n",
        "  lb = open(label_path, 'r')\n",
        "  data = lb.readlines()\n",
        "  lb.close()\n",
        "\n",
        "  for dt in data:\n",
        "    if flag == 0:\n",
        "      _, x, y, w, h = map(float, dt.split(' '))\n",
        "    else:\n",
        "      _, x, y, w, h, conf = map(float, dt.split(' '))\n",
        "    l = int((x - w / 2) * dw)\n",
        "    r = int((x + w / 2) * dw)\n",
        "    t = int((y - h / 2) * dh)\n",
        "    b = int((y + h / 2) * dh)\n",
        "    if flag == 0:\n",
        "      cv2.rectangle(img, (l, t), (r, b), (0, 250, 0), 2)\n",
        "    else:\n",
        "      cv2.rectangle(img, (l, t), (r, b), (0, 0, 250), 2)\n",
        "    \n",
        "  # plot_fig(img)\n",
        "  return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9LwyBDyvqjv"
      },
      "source": [
        "Word Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzQCHaLevphJ"
      },
      "outputs": [],
      "source": [
        "class word_segmentation:\n",
        "    def __init__(self, loc, loc1):\n",
        "        self.img_loc = loc1\n",
        "        self.lb_loc = loc+'labels/'\n",
        "        self.line_img = os.listdir(self.img_loc)\n",
        "        # self.line_img.remove('labels')\n",
        "        self.line_lb = os.listdir(self.lb_loc)\n",
        "        self.segmentation()\n",
        "\n",
        "    def arrange_img_with_lb(self):\n",
        "        img_lb = {}\n",
        "        for img in self.line_img:\n",
        "            for lb in self.line_lb:\n",
        "                st_img = img.split('.')[0]\n",
        "                st_lb = lb.split('.')[0]\n",
        "                if st_img == st_lb:\n",
        "                    img_lb[img] = lb\n",
        "        return img_lb\n",
        "\n",
        "    def segmentation(self):\n",
        "        img_with_lb = self.arrange_img_with_lb()\n",
        "        for image, label in img_with_lb.items():\n",
        "            new_folder = image.split('.')[0]\n",
        "            new_folder_loc = self.lb_loc + new_folder\n",
        "            os.mkdir(new_folder_loc)\n",
        "            current_img = self.img_loc+image\n",
        "            img = cv2.imread(current_img)\n",
        "            dh, dw, _ = img.shape\n",
        "            current_txt = self.lb_loc + label\n",
        "            fl = open(current_txt, 'r')\n",
        "            data = fl.readlines()\n",
        "            fl.close()\n",
        "            word_bb = []\n",
        "            for wd in data:\n",
        "                token = wd.strip().split()\n",
        "                word_bb.append(token)\n",
        "            sorted_word_bb = sorted(word_bb, key=operator.itemgetter(1))\n",
        "            k = 1\n",
        "\n",
        "            # Writing Sorted Files...\n",
        "            self.file_write(sorted_word_bb, label)\n",
        "\n",
        "            for rect in sorted_word_bb:\n",
        "                x = float(rect[1])\n",
        "                y = float(rect[2])\n",
        "                w = float(rect[3])\n",
        "                h = float(rect[4])\n",
        "                # if w > 0.50:\n",
        "                #   continue\n",
        "                l = int((x - w / 2) * dw)\n",
        "                r = int((x + w / 2) * dw)\n",
        "                t = int((y - h / 2) * dh)\n",
        "                b = int((y + h / 2) * dh)\n",
        "                crop = img[t:b, l:r]\n",
        "                cv2.imwrite(\"{}{}/{}_{}.jpg\".format(self.lb_loc, new_folder, new_folder, k), crop)\n",
        "                k += 1\n",
        "\n",
        "    def file_write(self,txt_file, file_name):\n",
        "        loc = '/content/Final_Results/sorted_word_labels/'+file_name\n",
        "        with open(loc, 'w') as f: \n",
        "            c=0\n",
        "            for line in txt_file:  \n",
        "                for l in line:\n",
        "                    c+=1\n",
        "                    if c == len(line):\n",
        "                        f.write('%s' % l)\n",
        "                    else:\n",
        "                        f.write('%s ' % l)\n",
        "                f.write(\"\\n\")\n",
        "                c=0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCjImgwa6l-Y"
      },
      "outputs": [],
      "source": [
        "# Sorted word label location...\n",
        "loc2 = '/content/Final_Results/sorted_word_labels/'\n",
        "os.mkdir(loc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wOL9C3tSwk5i"
      },
      "outputs": [],
      "source": [
        "loc = '/content/Final_Results/Final_word_segmentation_result/'\n",
        "loc1 = '/content/Final_Results/Final_Line_Segmentation/'\n",
        "obj = word_segmentation(loc, loc1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAUPJZjkHEj8"
      },
      "source": [
        "Sorting the lines with word Bounding Box..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJS98WVYEC9l"
      },
      "outputs": [],
      "source": [
        "filenm = \"/content/Final_Results/Final_Word_BB/\" \n",
        "os.mkdir(filenm)\n",
        "img_path = \"/content/Final_Results/Final_Line_Segmentation/\" \n",
        "label_path = \"/content/Final_Results/sorted_word_labels/\" \n",
        "flag = 1\n",
        "img_list = os.listdir(img_path)\n",
        "lbl_list = os.listdir(label_path)\n",
        "print(len(img_list))\n",
        "print(len(lbl_list))\n",
        "for i in img_list:\n",
        "  temp = i.split('.')[0]\n",
        "  txt_file = temp + '.txt'\n",
        "  img_path1 = img_path + i\n",
        "  label_path1 = label_path + txt_file\n",
        "  img = draw_BB(img_path1, label_path1, flag)\n",
        "  filenm1 = filenm + i\n",
        "  cv2.imwrite(filenm1, img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdIQCy1INW8O"
      },
      "source": [
        "# **Saving Results** (If want to save the generated outputs: Please uncomment the last code section and assign directory of any folder of your drive to the defined 'final_save' variable.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3lCff4Nbgfz"
      },
      "outputs": [],
      "source": [
        "# Copy content from one directory to another...\n",
        "from_dir = \"/content/yolov5/runs/detect\"\n",
        "to_dir = \"/content/Final_Results/All_detect\"\n",
        "copy_dir(from_dir, to_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE50SCUq6Jvk"
      },
      "outputs": [],
      "source": [
        "# Copy content from one directory to another...\n",
        "from_dir = \"/content/croped_line_after_1st_detection\"\n",
        "to_dir = \"/content/Final_Results/Initial Line Segmentation\"\n",
        "copy_dir(from_dir, to_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7JMv4B-ga1L"
      },
      "outputs": [],
      "source": [
        "zip_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmcQDYaRBXMb"
      },
      "source": [
        "To save the results, remove command from the cell below and put your desire drive path to the variable named \"final_save\" ,and run the below cell. Generated output is saved on this location as zip file: \"/content/test_results/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqtx74U-axbb"
      },
      "outputs": [],
      "source": [
        "# # Mounting Drive...\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# final_save = \"/content/drive/MyDrive/thesis/Transition_Outputs/\"\n",
        "# final_dir = \"/content/test_results/\"\n",
        "# %cp -rip $final_dir $final_save\n",
        "# print(\"Saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwtD8vC22LNK"
      },
      "source": [
        "Or you can remove this below cells commants and run it to download the zip, although **we do not recommend this** as it might take more than couple of hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOgwIJ192y7c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"/content/test_results/Final_Results.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
